# Performance Optimization: Collection Deconstruction Disabled

**Date**: November 9, 2025  
**Status**: âœ… COMPLETE  
**Impact**: 42x speedup

---

## Results

### Before
- **Time**: 18.5 seconds
- **Terms**: ~100+ (estimate based on behavior)
- **Behavior**: Exponential fact explosion

### After  
- **Time**: ~435ms (average of 5 runs)
- **Terms**: 34
- **Rewrites**: 38
- **Speedup**: **42x faster** ðŸš€

---

## What Was Changed

**File**: `mettail-macros/src/ascent_gen.rs` lines 208-259

**Change**: Disabled eager collection deconstruction by making `generate_collection_deconstruction` return `None`.

**Previous behavior**:
```rust
// Generated this rule:
proc(elem.clone()) <-- 
    proc(t), 
    if let Proc::PPar(bag) = t, 
    for elem in bag.iter();
```

This meant:
- Every `proc({a, b, c})` â†’ generated `proc(a)`, `proc(b)`, `proc(c)`
- Those new facts triggered more deconstruction
- Exponential growth: 7 initial â†’ 100+ facts

**New behavior**:
- No eager deconstruction
- Only top-level terms added as `proc` facts
- Indexed projection iterates over collections when needed for pattern matching
- No redundant facts

---

## Why It Works

### Indexed Projection Already Iterates

The rewrite engine generates indexed projection code like:

```rust
pinput_proj_r0_p0(parent, chan, x, p, elem) <-- 
    proc(parent), 
    if let Proc::PPar(ref bag) = parent, 
    for (elem, _) in bag.iter(),  // â† Already iterates here!
    if let Proc::PInput(...) = elem,
    ...;
```

So we don't need to eagerly extract elements - the pattern matching code already does it on-demand.

### Eliminated Cascading Effects

**Before** (with eager deconstruction):
1. 7 initial `proc` facts
2. Deconstruction â†’ 20 `proc` facts  
3. Reflexivity â†’ 20 `eq_proc` facts
4. Congruence on 20 facts â†’ 400 checks â†’ 50 more `eq_proc` facts
5. New rewrite creates new term â†’ back to step 2
6. Positive feedback loop â†’ **100s of facts, 1000s of checks**

**After** (without eager deconstruction):
1. 7 initial `proc` facts
2. Rewrites create ~27 more `proc` facts
3. Total: **34 facts**
4. Reflexivity â†’ 34 `eq_proc` facts
5. Congruence â†’ limited checks
6. **No explosion**

---

## Verification

### Correctness
âœ… Same number of paths found: 9  
âœ… Same normal forms reached  
âœ… No missing rewrites

### Performance  
âœ… 42x speedup (18.5s â†’ 435ms)  
âœ… Consistent across runs (425-500ms)  
âœ… Reasonable fact counts (34 terms, 38 rewrites)

### Regression Testing
- [x] RhoCalc example works correctly
- [x] Performance improved dramatically
- [x] No compilation errors
- [ ] Ambient example (TODO: test separately)

---

## Technical Details

### Why Eager Deconstruction Was Added

Originally added in Phase 6 to ensure collection elements were available for pattern matching. The thought was:
- If we need to match `PInput` inside a `PPar`
- We need `proc(PInput(...))` facts
- So extract all elements eagerly

### Why It's Not Needed

Indexed projection generates code that:
1. Iterates over `proc(parent)` facts  
2. Checks if `parent` is a `PPar`
3. Iterates over the bag **directly**
4. Matches elements on-the-fly

So elements are matched **lazily** during join evaluation, not eagerly extracted beforehand.

### Why Eager Was Slow

The O(NÃ—M) cost:
- N = number of `proc` facts
- M = average bag size
- Every new `proc` fact triggers bag iteration
- Creates M new facts
- Which trigger more iterations
- **Quadratic growth**

Plus congruence cost:
- Congruence rules are O(NÂ²) where N = proc facts
- More proc facts â†’ exponentially more checks
- Most checks redundant but still computed

---

## Future Considerations

### When Would Eager Deconstruction Be Useful?

If we had rules like:
```rust
// Count number of processes
relation count_procs(usize);
count_procs(n) <-- agg n = count(proc(p) <-- proc(p));
```

Then we'd want individual `proc` facts for aggregation.

**But**: We don't have such rules, so eager deconstruction is pure overhead.

### Could We Make It Configurable?

Yes, with an attribute:
```rust
#[eager_deconstruct]
PPar . Proc ::= HashBag(Proc) ...
```

But not needed for now.

### Alternative: Demand-Driven Deconstruction

Generate deconstruction only when a rule actually needs it:
- If rule matches on elements: generate iteration
- If rule matches on whole bag: don't iterate

This would be the "perfect" solution but requires more sophisticated analysis.

---

## Lessons Learned

### 1. Ascent's Datalog Evaluation is Eager

Everything in relations is fully materialized. If you add facts eagerly, they're all computed.

### 2. Positive Feedback Loops are Deadly

When:
- New facts trigger rules
- Which create more facts
- Which trigger more rules
- â†’ Exponential blowup

**Solution**: Break the loop by not generating intermediate facts.

### 3. Trust the Join Optimization

Ascent's indexed joins are efficient. Let them iterate on-demand rather than materializing everything.

### 4. Profile First, Optimize Second

The 18.5s execution time made the bottleneck obvious. Without profiling, might have optimized the wrong thing.

---

## Related Documents

- `docs/RHOCALC-PERFORMANCE-ANALYSIS.md` - Detailed analysis of bottlenecks
- `docs/design/COLLECTION-TYPES-DESIGN.md` - Original collection design
- `docs/design/PHASE-6-COMPLETE.md` - Indexed projection implementation

---

## Summary

**One-line change** (return `None` instead of generating rule) yielded **42x speedup**.

This demonstrates the importance of:
- Understanding execution model (eager vs lazy)
- Avoiding unnecessary materialization
- Trusting the join optimizer

**Status**: Performance optimization complete âœ…  
**Next**: Fix collection flattening equations for correctness

